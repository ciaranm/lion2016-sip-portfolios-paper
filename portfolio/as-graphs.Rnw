\documentclass{article}

\usepackage{booktabs}
\usepackage{hyperref}

\title{Algorithm Selection for Graph Algorithms}

\author{}

\begin{document}

\maketitle

<<echo=FALSE, message=FALSE, warning=FALSE>>=
opts_chunk$set(comment=NA, fig.width='\\textwidth', fig.height=5, fig.pos='!ht')
library(llama)
library(BBmisc)
library(xtable)
library(plyr)
library(aslib)

library(parallelMap)
parallelStartSocket(4)
parallelLibrary("llama", "mlr")
@

\section*{Data Analysis}

<<echo=FALSE, results='asis'>>=
#source("convertToAslib.R")

asscenario = parseASScenario("graphs-2015")
ldf = convertToLlamaCVFolds(asscenario)
# add family information
times = read.table("gpgnode-sip-runtimes.data", header = TRUE, sep = " ", stringsAsFactors = FALSE)
timess = times
times$family = factor(times$family)
ldf$data$family = times[order(times$instance, as.character(ldf$data$instance_id)), 'family']
ldf$extra = "family"

tab = t(sapply(ldf$data[,ldf$performance], mean))
print(xtable(tab, caption = "Mean performance of each algorithm."), booktabs = TRUE, include.rownames = FALSE)

tabs = by(ldf$data, ldf$data$family, function(x) as.data.frame.matrix(t(sapply(x[,ldf$performance], mean))))
tab = rbind.fill(tabs)
tab$family = rownames(tab)
tab = tab[,order(names(tab))]
print(xtable(tab, digits = 3, caption = "Mean performance by family."), booktabs = TRUE, include.rownames = FALSE)

tab = t(sapply(ldf$data[,ldf$performance], median))
print(xtable(tab, caption = "Median performance of each algorithm."), booktabs = TRUE, include.rownames = FALSE)

tabs = by(ldf$data, ldf$data$family, function(x) as.data.frame.matrix(t(sapply(x[,ldf$performance], median))))
tab = rbind.fill(tabs)
tab$family = rownames(tab)
tab = tab[,order(names(tab))]
print(xtable(tab, digits = 3, caption = "Median performance by family."), booktabs = TRUE, include.rownames = FALSE)

tab = t(table(unlist(ldf$best)))
print(xtable(tab, caption = "Number of times each algorithm is best. More than one algorithm may be best for one instance if there are ties."), booktabs = TRUE, include.rownames = FALSE)

tabs = tapply(ldf$best, ldf$data$family, function(x) as.data.frame.matrix(t(table(unlist(x)))))
tab = rbind.fill(tabs)
tab[is.na(tab)] = 0
tab$family = rownames(tab)
tab = tab[,order(names(tab))]
print(xtable(tab, digits = 0, caption = "Number of times each algorithm is best by family."), booktabs = TRUE, include.rownames = FALSE)
@

\clearpage

\section*{Exploratory Data Analysis}

\subsection*{Algorithms}

\subsubsection*{Overview of performance values}

The following statistics were calculated from the performance values of each alg
orithm:

\begin{itemize}
  \item obs (number of observations within performance values)
  \item nas (number of NAs, i.e.\ missing values, within performance values)
  \item min (minimum), mean (arithmetic mean), max (maximum), sd (standard deviation)
  \item qu\_1st (1st quartile = lower quartile = 25\%-quantile)
  \item med (median = 50\%-quantile)
  \item qu\_3rd (3rd quartile = upper quartile = 75\%-quantile)
  \item coeff\_var (coefficient of variation = standard deviation / arithmetic mean)
\end{itemize}

<<echo=FALSE, results='asis'>>=
source("eda_config.R")
config = readEDAConfig(asscenario, ".")

res = summarizeAlgoPerf(asscenario)
print(xtable(res, digits = 6, display = c("s", "d", "d", rep("g", 8))), booktabs = TRUE)
@

\subsubsection*{Summary of the runstatus per algorithm}

The following table summarizes the runstatus of each algorithm over all instances (in \%).

<<echo=FALSE, results='asis'>>=
res = summarizeAlgoRunstatus(asscenario)
print(xtable(res, digits = 3), booktabs = TRUE)
@

\subsubsection*{Dominated Algorithms}

<<echo=FALSE, results='asis'>>=
res = findDominatedAlgos(asscenario, reduce = TRUE, type = "character")
if (nrow(res) != 0) {
  print(xtable(res), include.rownames = TRUE, "html")
} else {
  cat("None of the algorithms was superior to any of the other.")
}
@

An algorithm (A) is considered to be superior to an other algorithm (B), if it
has at least an equal performance on all instances (compared to B) and if
it is better on at least one of them. A missing value is automatically a worse
performance. However, instances which could not be solved by either one of the
algorithms, were not considered for the dominance relation.

\subsubsection*{Boxplot of performance values}

Important note w.r.t.\ some of the following plots:
If appropriate, we imputed performance values for failed runs.
We used $max + 0.3 * (max - min)$, in case of minimization problems,
or $min - 0.3 * (max - min)$, in case of maximization problems.

In addition, a small noise is added to the imputed values (except for the
cluster matrix, based on correlations, which is shown at the end of this page).

<<echo=FALSE, fig.cap="Performance values with imputation.", message=FALSE>>=
plotAlgoPerfBoxplots(asscenario, impute.zero.vals = config$algo.perf.impute.zero.vals, log = config$algo.perf.log)
@

<<echo=FALSE, fig.cap="Cumulative density plot of performance values with imputation.", message=FALSE>>=
plotAlgoPerfCDFs(asscenario, impute.zero.vals = config$algo.perf.impute.zero.vals, log = config$algo.perf.log)
@

<<echo=FALSE, fig.cap="Performance values without imputation.", message=FALSE>>=
plotAlgoPerfScatterMatrix(asscenario, impute.zero.vals = config$algo.perf.impute.zero.vals, log = config$algo.perf.log)
@

The figure showing the correlations of the ranks of the performance values shows
the Spearman correlation coefficient. Missing values were imputed prior to
computing the correlation coefficients. The algorithms are ordered in a way that
similar (highly correlated) algorithms are close to each other. Per default the
clustering is based on hierarchical clustering, using Ward's method.

<<echo=FALSE, fig.cap="Algorithm correlation clusters.", message=FALSE>>=
plotAlgoCorMatrix(asscenario)
@

\clearpage

\subsection*{Features}

\subsubsection*{Overview of Feature Values}

The following measures were taken for the results of each feature:

\begin{itemize}
  \item obs (number of observations within the feature set)
  \item NAs (number of NAs, i.e. missing values, within the feature set)
  \item min (minimum), mean (arithmetic mean), max (maximum), std\_dev (standard deviation)
  \item 1st\_qu (1st quartile = lower quartile = 25\%-quantile)
  \item median (median = 50\%-quantile)
  \item 3rd\_qu (3rd quartile = upper quartile = 75\%-quantile)
  \item co\_var (coefficient of variation = standard deviation / arithmetic mean)
\end{itemize}

<<echo=FALSE, results='asis'>>=
res = summarizeFeatureValues(asscenario)
print(xtable(res, display = c("s", "d", "d", rep("g", 8))), booktabs = TRUE)
@

\subsubsection*{Summary of feature steps}

The following table summarizes the feature steps over all instances.

\begin{itemize}
  \item size (percentage of features affected by this step)
  \item ok, \ldots, other (percentage of run status)
  \item cost\_min, cost\_mean, cost\_max (range of costs for this step)
  \item cost\_na (percentage of missing values occurring in costs)
\end{itemize}

<<echo=FALSE, results='asis'>>=
res = summarizeFeatureSteps(asscenario)
print(xtable(res, display = c("s", "d", rep("g", ncol(res) - 1L))), booktabs = TRUE)
@

%\subsubsection*{Duplicated Features}
%
%<<echo=FALSE, results='asis'>>=
%res = checkDuplicatedInstances(asscenario)
%if (length(res) > 0L) {
%  numbers = sapply(res, length)
%  res = sapply(seq_along(res), function(i) {
%    if (numbers[i] > 5)
%      res[[i]] = c(res[[i]][1:5], "...")
%    collapse(res[[i]], sep = " +++++++ ")
%  })
%  res = data.frame(block = seq_along(numbers), numbers = numbers, instances = res)
%  print(xtable(res), include.rownames = FALSE, booktabs = TRUE)
%} else {
%  cat("There were no duplicated features.")
%}
%@

\clearpage

\section*{Algorithm Selection Results}

<<echo=FALSE, results='asis', warning=FALSE, message=FALSE>>=
resvbs = data.frame(model = "virtual best",
    mean.performance = mean(parscores(ldf, vbs, factor = 1)),
    median.performance = median(parscores(ldf, vbs, factor = 1)))
ressb = data.frame(model = "single best",
    mean.performance = mean(parscores(ldf, singleBest, factor = 1)),
    median.performance = median(parscores(ldf, singleBest, factor = 1)))

modelc = classify(makeLearner("classif.randomForest"), ldf)
resc = data.frame(model = "classification",
    mean.performance = mean(parscores(ldf, modelc, factor = 1)),
    median.performance = median(parscores(ldf, modelc, factor = 1)))
times = sapply(modelc$models, function(x) row.names(sortByCol(as.data.frame(x$learner.model$importance), "MeanDecreaseGini", asc = FALSE))[1])
print(xtable(as.table(sort(table(times), decreasing = TRUE)), caption = "Most important features for classification."), booktabs = TRUE)

modelr = regression(makeLearner("regr.randomForest"), ldf)
resr = data.frame(model = "regression",
    mean.performance = mean(parscores(ldf, modelr, factor = 1)),
    median.performance = median(parscores(ldf, modelr, factor = 1)))
times = sapply(modelr$models, function(x) row.names(sortByCol(as.data.frame(x$learner.model$importance), "IncNodePurity", asc = FALSE))[1])
print(xtable(as.table(sort(table(times), decreasing = TRUE)), caption = "Most important features for regression."), booktabs = TRUE)

modelcp = classifyPairs(makeLearner("classif.randomForest"), ldf)
rescp = data.frame(model = "classifyPairs",
    mean.performance = mean(parscores(ldf, modelcp, factor = 1)),
    median.performance = median(parscores(ldf, modelcp, factor = 1)))
times = sapply(modelcp$models, function(x) row.names(sortByCol(as.data.frame(x$learner.model$importance), "MeanDecreaseGini", asc = FALSE))[1])
print(xtable(as.table(sort(table(times), decreasing = TRUE)), caption = "Most important features for classificationPairs."), booktabs = TRUE)

modelrp = regressionPairs(makeLearner("regr.randomForest"), ldf)
resrp = data.frame(model = "regressionPairs",
    mean.performance = mean(parscores(ldf, modelrp, factor = 1)),
    median.performance = median(parscores(ldf, modelrp, factor = 1)))
times = sapply(modelrp$models, function(x) row.names(sortByCol(as.data.frame(x$learner.model$importance), "IncNodePurity", asc = FALSE))[1])
print(xtable(as.table(sort(table(times), decreasing = TRUE)), caption = "Most important features for regressionPairs."), booktabs = TRUE)

tab = rbind(resvbs, ressb, resc, resr, rescp, resrp)
print(xtable(tab, digits = 3, caption = "Preliminary algorithm selection results."), booktabs = TRUE, include.rownames = FALSE)
@

<<echo=FALSE,fig.cap='Single best algorithm vs.\ portfolio performance (best model).'>>=
best = which.min(c(resc$mean.performance, resr$mean.performance, rescp$mean.performance, resrp$mean.performance))
mod = list(modelc, modelr, modelcp, modelrp)[[best]]
perfScatterPlot(parscores, mod, singleBest, ldf, addCostsx = TRUE, addCostsy = FALSE, factor = 1, pargs=aes(colour = family)) + scale_x_log10() + scale_y_log10() + xlab("portfolio") + ylab("single best")
@

\clearpage

\subsection*{Algorithm Selection Results with instances solved during
computation of LAD features removed}

<<echo=FALSE, results='asis', warning=FALSE, message=FALSE>>=
ldf3 = ldf
presolved = asscenario$feature.runstatus$instance_id[asscenario$feature.runstatus$lad_features == "presolved"]
ldf3$data = subset(ldf$data, !(ldf$data$instance_id %in% presolved))
ldf3$best = subset(ldf$best, !(ldf$data$instance_id %in% presolved))
ldf3$train = NULL
ldf3$test = NULL
ldf3 = cvFolds(ldf3)
timess2 = subset(timess, timess$instance %in% ldf3$data$instance_id)
ldf3$data$family = factor(timess2[order(timess2$instance, as.character(ldf3$data$instance_id)), 'family'])
ldf3$extra = "family"

tab = t(sapply(ldf3$data[,ldf3$performance], mean))
print(xtable(tab, caption = "Mean performance of each algorithm."), booktabs = TRUE, include.rownames = FALSE)

tabs = by(ldf3$data, ldf3$data$family, function(x) as.data.frame.matrix(t(sapply(x[,ldf3$performance], mean))))
tab = rbind.fill(tabs)
tab$family = rownames(tab)
tab = tab[,order(names(tab))]
print(xtable(tab, digits = 3, caption = "Mean performance by family."), booktabs = TRUE, include.rownames = FALSE)

tab = t(sapply(ldf3$data[,ldf3$performance], median))
print(xtable(tab, caption = "Median performance of each algorithm."), booktabs = TRUE, include.rownames = FALSE)

tabs = by(ldf3$data, ldf3$data$family, function(x) as.data.frame.matrix(t(sapply(x[,ldf3$performance], median))))
tab = rbind.fill(tabs)
tab$family = rownames(tab)
tab = tab[,order(names(tab))]
print(xtable(tab, digits = 3, caption = "Median performance by family."), booktabs = TRUE, include.rownames = FALSE)

tab = t(table(unlist(ldf3$best)))
print(xtable(tab, caption = "Number of times each algorithm is best. More than one algorithm may be best for one instance if there are ties."), booktabs = TRUE, include.rownames = FALSE)

tabs = tapply(ldf3$best, ldf3$data$family, function(x) as.data.frame.matrix(t(table(unlist(x)))))
tab = rbind.fill(tabs)
tab[is.na(tab)] = 0
tab$family = rownames(tab)
tab = tab[,order(names(tab))]
print(xtable(tab, digits = 0, caption = "Number of times each algorithm is best by family."), booktabs = TRUE, include.rownames = FALSE)
@

\clearpage

<<echo=FALSE, results='asis', warning=FALSE, message=FALSE>>=
resvbs = data.frame(model = "virtual best",
    mean.performance = mean(parscores(ldf3, vbs, factor = 1)),
    median.performance = median(parscores(ldf3, vbs, factor = 1)))
ressb = data.frame(model = "single best",
    mean.performance = mean(parscores(ldf3, singleBest, factor = 1)),
    median.performance = median(parscores(ldf3, singleBest, factor = 1)))

modelc = classify(makeLearner("classif.randomForest"), ldf3)
resc = data.frame(model = "classification",
    mean.performance = mean(parscores(ldf3, modelc, factor = 1)),
    median.performance = median(parscores(ldf3, modelc, factor = 1)))
times = sapply(modelc$models, function(x) row.names(sortByCol(as.data.frame(x$learner.model$importance), "MeanDecreaseGini", asc = FALSE))[1])
print(xtable(as.table(sort(table(times), decreasing = TRUE)), caption = "Most important features for classification."), booktabs = TRUE)

modelr = regression(makeLearner("regr.randomForest"), ldf3)
resr = data.frame(model = "regression",
    mean.performance = mean(parscores(ldf3, modelr, factor = 1)),
    median.performance = median(parscores(ldf3, modelr, factor = 1)))
times = sapply(modelr$models, function(x) row.names(sortByCol(as.data.frame(x$learner.model$importance), "IncNodePurity", asc = FALSE))[1])
print(xtable(as.table(sort(table(times), decreasing = TRUE)), caption = "Most important features for regression."), booktabs = TRUE)

modelcp = classifyPairs(makeLearner("classif.randomForest"), ldf3)
rescp = data.frame(model = "classifyPairs",
    mean.performance = mean(parscores(ldf3, modelcp, factor = 1)),
    median.performance = median(parscores(ldf3, modelcp, factor = 1)))
times = sapply(modelcp$models, function(x) row.names(sortByCol(as.data.frame(x$learner.model$importance), "MeanDecreaseGini", asc = FALSE))[1])
print(xtable(as.table(sort(table(times), decreasing = TRUE)), caption = "Most important features for classificationPairs."), booktabs = TRUE)

modelrp = regressionPairs(makeLearner("regr.randomForest"), ldf3)
resrp = data.frame(model = "regressionPairs",
    mean.performance = mean(parscores(ldf3, modelrp, factor = 1)),
    median.performance = median(parscores(ldf3, modelrp, factor = 1)))
times = sapply(modelrp$models, function(x) row.names(sortByCol(as.data.frame(x$learner.model$importance), "IncNodePurity", asc = FALSE))[1])
print(xtable(as.table(sort(table(times), decreasing = TRUE)), caption = "Most important features for regressionPairs."), booktabs = TRUE)

tab = rbind(resvbs, ressb, resc, resr, rescp, resrp)
print(xtable(tab, digits = 3, caption = "Preliminary algorithm selection results with presolver."), booktabs = TRUE, include.rownames = FALSE)
@

<<echo=FALSE,fig.cap='Single best algorithm vs.\ portfolio performance with presolved instances removed (best model).'>>=
best = which.min(c(resc$mean.performance, resr$mean.performance, rescp$mean.performance, resrp$mean.performance))
mod = list(modelc, modelr, modelcp, modelrp)[[best]]
perfScatterPlot(parscores, mod, singleBest, ldf3, factor = 1, pargs=aes(colour = family)) + scale_x_log10() + scale_y_log10() + xlab("portfolio") + ylab("single best")
@

\clearpage

\subsection*{Algorithm Selection Results with Presolver}

Run vf2 for 0.05 second as a presolver, after removing presolved instances.

<<echo=FALSE, results='asis', warning=FALSE, message=FALSE>>=
# presolver
ldf2 = ldf3
presolvetime = 0.05
ldf2$data = subset(ldf3$data, ldf3$data$vf2 > presolvetime)
ldf2$best = subset(ldf3$best, ldf3$data$vf2 > presolvetime)
ldf2$train = NULL
ldf2$test = NULL
ldf2 = cvFolds(ldf2)
timesss = subset(timess, timess$instance %in% ldf2$data$instance_id)
ldf2$data$family = factor(timesss[order(timesss$instance, as.character(ldf2$data$instance_id)), 'family'])
ldf2$extra = "family"

tab = t(sapply(ldf2$data[,ldf2$performance], mean))
print(xtable(tab, caption = "Mean performance of each algorithm."), booktabs = TRUE, include.rownames = FALSE)

tabs = by(ldf2$data, ldf2$data$family, function(x) as.data.frame.matrix(t(sapply(x[,ldf2$performance], mean))))
tab = rbind.fill(tabs)
tab$family = rownames(tab)
tab = tab[,order(names(tab))]
print(xtable(tab, digits = 3, caption = "Mean performance by family."), booktabs = TRUE, include.rownames = FALSE)

tab = t(sapply(ldf2$data[,ldf2$performance], median))
print(xtable(tab, caption = "Median performance of each algorithm."), booktabs = TRUE, include.rownames = FALSE)

tabs = by(ldf2$data, ldf2$data$family, function(x) as.data.frame.matrix(t(sapply(x[,ldf2$performance], median))))
tab = rbind.fill(tabs)
tab$family = rownames(tab)
tab = tab[,order(names(tab))]
print(xtable(tab, digits = 3, caption = "Median performance by family."), booktabs = TRUE, include.rownames = FALSE)

tab = t(table(unlist(ldf2$best)))
print(xtable(tab, caption = "Number of times each algorithm is best. More than one algorithm may be best for one instance if there are ties."), booktabs = TRUE, include.rownames = FALSE)

tabs = tapply(ldf2$best, ldf2$data$family, function(x) as.data.frame.matrix(t(table(unlist(x)))))
tab = rbind.fill(tabs)
tab[is.na(tab)] = 0
tab$family = rownames(tab)
tab = tab[,order(names(tab))]
print(xtable(tab, digits = 0, caption = "Number of times each algorithm is best by family."), booktabs = TRUE, include.rownames = FALSE)
@

\clearpage

<<echo=FALSE, results='asis', warning=FALSE, message=FALSE>>=
resvbs = data.frame(model = "virtual best",
    mean.performance = mean(parscores(ldf2, vbs, factor = 1)),
    median.performance = median(parscores(ldf2, vbs, factor = 1)))
ressb = data.frame(model = "single best",
    mean.performance = mean(parscores(ldf2, singleBest, factor = 1)),
    median.performance = median(parscores(ldf2, singleBest, factor = 1)))

modelc = classify(makeLearner("classif.randomForest"), ldf2)
resc = data.frame(model = "classification",
    mean.performance = mean(parscores(ldf2, modelc, factor = 1)),
    median.performance = median(parscores(ldf2, modelc, factor = 1)))
times = sapply(modelc$models, function(x) row.names(sortByCol(as.data.frame(x$learner.model$importance), "MeanDecreaseGini", asc = FALSE))[1])
print(xtable(as.table(sort(table(times), decreasing = TRUE)), caption = "Most important features for classification."), booktabs = TRUE)

modelr = regression(makeLearner("regr.randomForest"), ldf2)
resr = data.frame(model = "regression",
    mean.performance = mean(parscores(ldf2, modelr, factor = 1)),
    median.performance = median(parscores(ldf2, modelr, factor = 1)))
times = sapply(modelr$models, function(x) row.names(sortByCol(as.data.frame(x$learner.model$importance), "IncNodePurity", asc = FALSE))[1])
print(xtable(as.table(sort(table(times), decreasing = TRUE)), caption = "Most important features for regression."), booktabs = TRUE)

modelcp = classifyPairs(makeLearner("classif.randomForest"), ldf2)
rescp = data.frame(model = "classifyPairs",
    mean.performance = mean(parscores(ldf2, modelcp, factor = 1)),
    median.performance = median(parscores(ldf2, modelcp, factor = 1)))
times = sapply(modelcp$models, function(x) row.names(sortByCol(as.data.frame(x$learner.model$importance), "MeanDecreaseGini", asc = FALSE))[1])
print(xtable(as.table(sort(table(times), decreasing = TRUE)), caption = "Most important features for classificationPairs."), booktabs = TRUE)

modelrp = regressionPairs(makeLearner("regr.randomForest"), ldf2)
resrp = data.frame(model = "regressionPairs",
    mean.performance = mean(parscores(ldf2, modelrp, factor = 1)),
    median.performance = median(parscores(ldf2, modelrp, factor = 1)))
times = sapply(modelrp$models, function(x) row.names(sortByCol(as.data.frame(x$learner.model$importance), "IncNodePurity", asc = FALSE))[1])
print(xtable(as.table(sort(table(times), decreasing = TRUE)), caption = "Most important features for regressionPairs."), booktabs = TRUE)

tab = rbind(resvbs, ressb, resc, resr, rescp, resrp)
print(xtable(tab, digits = 3, caption = "Preliminary algorithm selection results with presolver."), booktabs = TRUE, include.rownames = FALSE)
@

<<echo=FALSE,fig.cap='Single best algorithm vs.\ portfolio performance with presolver (best model).'>>=
best = which.min(c(resc$mean.performance, resr$mean.performance, rescp$mean.performance, resrp$mean.performance))
mod = list(modelc, modelr, modelcp, modelrp)[[best]]
perfScatterPlot(parscores, mod, singleBest, ldf2, factor = 1, pargs=aes(colour = family)) + scale_x_log10() + scale_y_log10() + xlab("portfolio") + ylab("single best")
@

<<echo=FALSE, message=FALSE, warning=FALSE>>=
parallelStop()
@

\end{document}
